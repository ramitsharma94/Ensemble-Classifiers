{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we will use the digits dataset from scikit-learn datasets library\n",
    "# Lets load the library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "digits = load_digits()\n",
    "data = digits.data\n",
    "labels = digits.target\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(data, labels, \n",
    "                                               test_size = 0.3,\n",
    "                                               random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here, we will use three classifiers Random Forest, SVC KNeighbors and then we will implement Voting classifier \n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "\n",
    "knn_clf = KNeighborsClassifier()\n",
    "svc_clf = SVC()\n",
    "mlp_clf = MLPClassifier()\n",
    "voting_clf = VotingClassifier(\n",
    "            estimators = [(\"knn\", knn_clf), (\"mlp\", mlp_clf),\n",
    "                         (\"svc\", svc_clf)],\n",
    "            voting = \"hard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier:\t99.26%\n",
      "SVC:\t98.70%\n",
      "MLPClassifier:\t98.52%\n",
      "VotingClassifier:\t98.89%\n"
     ]
    }
   ],
   "source": [
    "# Let us look at the accuracies of each classifier\n",
    "for clf in (knn_clf, svc_clf, mlp_clf, voting_clf):\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    y_pred = clf.predict(xtest)\n",
    "    print(\"{}:\\t{:.2f}%\".format(clf.__class__.__name__,accuracy_score(ytest, y_pred) * 100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score if we apply bootstrapping (Bagging):0.9314814814814815\n"
     ]
    }
   ],
   "source": [
    "## Bagging\n",
    "## We are using the same digits dataset \n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(RandomForestClassifier(), n_estimators = 1000,\n",
    "                           max_samples = 64, bootstrap =True, n_jobs = -1)\n",
    "\n",
    "bag_clf.fit(xtrain, ytrain)\n",
    "y_pred = bag_clf.predict(xtest)\n",
    "print(\"Accuracy score if we apply bootstrapping (Bagging):{}\".format(accuracy_score(ytest, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score if we use Pasting as an ensembling technique:0.9314814814814815\n"
     ]
    }
   ],
   "source": [
    "## Pasting\n",
    "## We are using the same digits dataset \n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(RandomForestClassifier(), n_estimators = 1000,\n",
    "                           max_samples = 64, bootstrap =False, n_jobs = -1)\n",
    "\n",
    "bag_clf.fit(xtrain, ytrain)\n",
    "y_pred = bag_clf.predict(xtest)\n",
    "print(\"Accuracy score if we use Pasting as an ensembling technique:{}\".format(accuracy_score(ytest, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9740740740740741\n"
     ]
    }
   ],
   "source": [
    "## Ada Boost \n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(RandomForestClassifier(), n_estimators = 500,learning_rate = 0.01)\n",
    "ada_clf.fit(xtrain, ytrain)\n",
    "y_pred = ada_clf.predict(xtest)\n",
    "print(\"Accuracy score of Ada Boost Classifier:{}\", accuracy_score(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of Gradient Boosting:  0.9611111111111111\n"
     ]
    }
   ],
   "source": [
    "## Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(n_estimators = 500, learning_rate = 0.01)\n",
    "gb_clf.fit(xtrain , ytrain)\n",
    "y_pred = gb_clf.predict(xtest)\n",
    "\n",
    "print(\"Accuracy score of Gradient Boosting: \", accuracy_score(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of XGBoost:  0.9648148148148148\n"
     ]
    }
   ],
   "source": [
    "## XGBoost \n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier(objective= \"softmax\")\n",
    "xgb_clf.fit(xtrain, ytrain)\n",
    "y_pred = xgb_clf.predict(xtest)\n",
    "print(\"Accuracy score of XGBoost: \", accuracy_score(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of Stacking Classifier:  0.9888888888888889\n"
     ]
    }
   ],
   "source": [
    "# Stacking Classifier\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "svc_clf = SVC()\n",
    "rf_clf = RandomForestClassifier()\n",
    "mlp_clf = MLPClassifier()\n",
    "\n",
    "estimators = [(\"svc\", svc_clf), (\"rf_clf\", rf_clf), (\"mlp_clf\", mlp_clf)]\n",
    "\n",
    "stacking_clf = StackingClassifier(estimators = estimators, final_estimator = RandomForestClassifier())\n",
    "stacking_clf.fit(xtrain, ytrain)\n",
    "y_pred = stacking_clf.predict(xtest)\n",
    "print(\"Accuracy score of Stacking Classifier: \", accuracy_score(ytest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
